{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A mini Machine Learning Project exploring feature and model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code will:    \n",
    "- Loads the data    \n",
    "- Performs feature and model selection (one table and two visualizations to present these results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loading all needed library\n",
    "\n",
    "from scipy.io import arff\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, ShuffleSplit, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attr1</th>\n",
       "      <th>Attr2</th>\n",
       "      <th>Attr3</th>\n",
       "      <th>Attr4</th>\n",
       "      <th>Attr5</th>\n",
       "      <th>Attr6</th>\n",
       "      <th>Attr7</th>\n",
       "      <th>Attr8</th>\n",
       "      <th>Attr9</th>\n",
       "      <th>Attr10</th>\n",
       "      <th>...</th>\n",
       "      <th>Attr56</th>\n",
       "      <th>Attr57</th>\n",
       "      <th>Attr58</th>\n",
       "      <th>Attr59</th>\n",
       "      <th>Attr60</th>\n",
       "      <th>Attr61</th>\n",
       "      <th>Attr62</th>\n",
       "      <th>Attr63</th>\n",
       "      <th>Attr64</th>\n",
       "      <th>bankrupt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.174190</td>\n",
       "      <td>0.41299</td>\n",
       "      <td>0.14371</td>\n",
       "      <td>1.3480</td>\n",
       "      <td>-28.9820</td>\n",
       "      <td>0.60383</td>\n",
       "      <td>0.219460</td>\n",
       "      <td>1.1225</td>\n",
       "      <td>1.1961</td>\n",
       "      <td>0.46359</td>\n",
       "      <td>...</td>\n",
       "      <td>0.163960</td>\n",
       "      <td>0.375740</td>\n",
       "      <td>0.83604</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>9.7145</td>\n",
       "      <td>6.2813</td>\n",
       "      <td>84.291</td>\n",
       "      <td>4.3303</td>\n",
       "      <td>4.0341</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.146240</td>\n",
       "      <td>0.46038</td>\n",
       "      <td>0.28230</td>\n",
       "      <td>1.6294</td>\n",
       "      <td>2.5952</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.171850</td>\n",
       "      <td>1.1721</td>\n",
       "      <td>1.6018</td>\n",
       "      <td>0.53962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027516</td>\n",
       "      <td>0.271000</td>\n",
       "      <td>0.90108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.9882</td>\n",
       "      <td>4.1103</td>\n",
       "      <td>102.190</td>\n",
       "      <td>3.5716</td>\n",
       "      <td>5.9500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.22612</td>\n",
       "      <td>0.48839</td>\n",
       "      <td>3.1599</td>\n",
       "      <td>84.8740</td>\n",
       "      <td>0.19114</td>\n",
       "      <td>0.004572</td>\n",
       "      <td>2.9881</td>\n",
       "      <td>1.0077</td>\n",
       "      <td>0.67566</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007639</td>\n",
       "      <td>0.000881</td>\n",
       "      <td>0.99236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.7742</td>\n",
       "      <td>3.7922</td>\n",
       "      <td>64.846</td>\n",
       "      <td>5.6287</td>\n",
       "      <td>4.4581</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.024526</td>\n",
       "      <td>0.43236</td>\n",
       "      <td>0.27546</td>\n",
       "      <td>1.7833</td>\n",
       "      <td>-10.1050</td>\n",
       "      <td>0.56944</td>\n",
       "      <td>0.024526</td>\n",
       "      <td>1.3057</td>\n",
       "      <td>1.0509</td>\n",
       "      <td>0.56453</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048398</td>\n",
       "      <td>0.043445</td>\n",
       "      <td>0.95160</td>\n",
       "      <td>0.142980</td>\n",
       "      <td>4.2286</td>\n",
       "      <td>5.0528</td>\n",
       "      <td>98.783</td>\n",
       "      <td>3.6950</td>\n",
       "      <td>3.4844</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.188290</td>\n",
       "      <td>0.41504</td>\n",
       "      <td>0.34231</td>\n",
       "      <td>1.9279</td>\n",
       "      <td>-58.2740</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.233580</td>\n",
       "      <td>1.4094</td>\n",
       "      <td>1.3393</td>\n",
       "      <td>0.58496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176480</td>\n",
       "      <td>0.321880</td>\n",
       "      <td>0.82635</td>\n",
       "      <td>0.073039</td>\n",
       "      <td>2.5912</td>\n",
       "      <td>7.0756</td>\n",
       "      <td>100.540</td>\n",
       "      <td>3.6303</td>\n",
       "      <td>4.6375</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Attr1    Attr2    Attr3   Attr4    Attr5    Attr6     Attr7   Attr8  \\\n",
       "0  0.174190  0.41299  0.14371  1.3480 -28.9820  0.60383  0.219460  1.1225   \n",
       "1  0.146240  0.46038  0.28230  1.6294   2.5952  0.00000  0.171850  1.1721   \n",
       "2  0.000595  0.22612  0.48839  3.1599  84.8740  0.19114  0.004572  2.9881   \n",
       "3  0.024526  0.43236  0.27546  1.7833 -10.1050  0.56944  0.024526  1.3057   \n",
       "4  0.188290  0.41504  0.34231  1.9279 -58.2740  0.00000  0.233580  1.4094   \n",
       "\n",
       "    Attr9   Attr10    ...       Attr56    Attr57   Attr58    Attr59  Attr60  \\\n",
       "0  1.1961  0.46359    ...     0.163960  0.375740  0.83604  0.000007  9.7145   \n",
       "1  1.6018  0.53962    ...     0.027516  0.271000  0.90108  0.000000  5.9882   \n",
       "2  1.0077  0.67566    ...     0.007639  0.000881  0.99236  0.000000  6.7742   \n",
       "3  1.0509  0.56453    ...     0.048398  0.043445  0.95160  0.142980  4.2286   \n",
       "4  1.3393  0.58496    ...     0.176480  0.321880  0.82635  0.073039  2.5912   \n",
       "\n",
       "   Attr61   Attr62  Attr63  Attr64  bankrupt  \n",
       "0  6.2813   84.291  4.3303  4.0341         0  \n",
       "1  4.1103  102.190  3.5716  5.9500         0  \n",
       "2  3.7922   64.846  5.6287  4.4581         0  \n",
       "3  5.0528   98.783  3.6950  3.4844         0  \n",
       "4  7.0756  100.540  3.6303  4.6375         0  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing data\n",
    "df = pd.read_csv(\"../data/data_clean.csv\")\n",
    "\n",
    "# Take a glance at the dataset:\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature and model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset has a few missing values so I will need to do some preprocessing to impute the missing values with the mean of each features. This is not an ideal way but it won't affect the result much since the number of missing values is relatively small (less than 10% for each feature that has missing values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Divide the dataset into traning and testing set with labels\n",
    "X = df.iloc[:,:-1].values\n",
    "y = df.iloc[:,63].values\n",
    "\n",
    "# splitting the set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  Imputing the missing values by the mean of the columns\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "imp.fit(X_train)\n",
    "\n",
    "X = imp.transform(X)\n",
    "\n",
    "# Split again:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st try out: Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting up\n",
    "threshold = 1e-6\n",
    "\n",
    "# Logistic Regression with L1 penalty\n",
    "clf1 = LogisticRegression(penalty = 'l1')\n",
    "# Logistic Regression with L1 penalty\n",
    "clf2 = LogisticRegression(penalty = 'l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation score of model 0.953355544979\n",
      "The number of selected feature of model 52\n",
      "The validation score of model 0.938124702523\n",
      "The number of selected feature of model 55\n"
     ]
    }
   ],
   "source": [
    "model_list = (clf1, clf2)\n",
    "\n",
    "for clf in model_list:\n",
    "    clf.fit(X_train, y_train)\n",
    "    feature_weight = clf.coef_\n",
    "    print(\"The validation score of model\",clf.score(X_test,y_test))\n",
    "    print(\"The number of selected feature of model\",(np.sum(abs(feature_weight) > threshold)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Out of 64 features, the first model chooses 54 features with higher validation score ($0.95$), so we will choose this model. Now I will perform a cross validation to find the best hyperparameter 'C':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameter is {'C': 0.001}\n",
      "The best score is 0.951440133302\n"
     ]
    }
   ],
   "source": [
    "listC = 10.0**np.arange(-4,4)\n",
    "parameter = {'C':listC}\n",
    "lr = LogisticRegression(penalty = 'l1')\n",
    "clf = GridSearchCV(lr, parameter)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"The best parameter is\",clf.best_params_)\n",
    "print(\"The best score is\",clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score of Logistic Regression model is 0.952035229707\n",
      "Testing score of Logistic Regression model is 0.955259400286\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(penalty = 'l1', C = 0.001)\n",
    "lr.fit(X_train, y_train)\n",
    "print(\"Training score of Logistic Regression model is\",lr.score(X_train, y_train))\n",
    "print(\"Testing score of Logistic Regression model is\",lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2nd try out: Decision Tree Classifier\n",
    "\n",
    "I will combine the average 10-fold cross-validation scores on the training dataset using sklearn's cross_val_score and the Decision Tree Classifier as the model to find the best estimator for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maxDepth = 50\n",
    "kFold = 10\n",
    "scores = np.zeros((maxDepth, kFold))\n",
    "\n",
    "for depth in np.arange(1, maxDepth + 1):\n",
    "    clf = DecisionTreeClassifier(max_depth=depth)\n",
    "    scores[depth - 1] = cross_val_score(clf, X_train, \n",
    "                                        y_train, cv=kFold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the results \n",
    "# Code from the lab1 solution\n",
    "plt.style.use('ggplot')\n",
    "plt.errorbar(range(1, maxDepth + 1), np.average(scores, axis=1), \n",
    "             color='orange', linestyle='--', marker='o', markersize=10, \n",
    "             yerr=np.std(scores, axis=1), ecolor='pink', \n",
    "             capthick=2)\n",
    "plt.xlabel(\"Maximum tree depth\", fontsize = 16)\n",
    "plt.ylabel(\"Average accuracy\", fontsize = 16)\n",
    "plt.title(\"Average accuracy on 10-Fold CV vs. Tree depth\", \n",
    "          fontsize = 20)\n",
    "plt.gcf().set_size_inches(12, 7)\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/tree1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross validation accuracies are very high in general, however we can see that the accuracy decreases when the tree depth increases and is quite stable after depth 20. So if an accuracy above 95% is desired, an estimator from depth $3$ to $14$ is a reasonable choice for this data.          \n",
    "Now I will try plotting the training and testing score with vs the depth of the tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainging_scores = np.zeros((maxDepth, 1))\n",
    "testing_scores = np.zeros((maxDepth, 1))\n",
    "\n",
    "for depth in np.arange(1, maxDepth + 1):\n",
    "    clf = DecisionTreeClassifier(max_depth=depth)\n",
    "    clf.fit(X_train, y_train)\n",
    "    trainging_scores[depth - 1] = clf.score(X_train, y_train)\n",
    "    testing_scores[depth - 1] = clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "plt.style.use('ggplot')\n",
    "plt.plot(range(1, maxDepth + 1), trainging_scores, 'o--', \n",
    "         markersize=10, color='orange', lw=1, label='Training accuracy')\n",
    "plt.plot(range(1, maxDepth + 1), testing_scores, 'o--',\n",
    "         markersize=10, color='red', lw=1, label='Testing accuracy')\n",
    "plt.xlabel(\"Maximum tree depth\", fontsize = 16)\n",
    "plt.ylabel(\"Average accuracy\", fontsize = 16)\n",
    "plt.title(\"Training and Testing accuracy vs. Tree depth\", \n",
    "          fontsize = 20)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.gcf().set_size_inches(12, 8)\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/tree2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a much more interesting graph. It can be seen that after depth $20$, the model is definitely overfitting. However, the accuracies are relatively high for both training and testing accuracy from the very beginning, so depth from $1$ to $15$ is advisable. Now I will create the model with the parameter chosen from the test above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=3)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Training score of Decision Tree Classifier is\",clf.score(X_train, y_train))\n",
    "print(\"Testing score of Decision Tree Classifier is\",clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last try out: A simple ordinary least squares model.\n",
    "\n",
    "This model will help me see which features is more significant in the dataset by the p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "lm = sm.OLS(y_train,X_train).fit()\n",
    "print(lm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.rc('figure', figsize=(7, 15))\n",
    "plt.text(0.01, 0.05, str(lm.summary()), {'fontsize': 10}, fontproperties = 'monospace') # approach improved by OP -> monospace!\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/feature_table.png')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
